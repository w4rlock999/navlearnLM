{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is the scratchpad and testing for the server code of navlearnLM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\w4rlo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3526, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\w4rlo\\AppData\\Local\\Temp\\ipykernel_3696\\1650443214.py\", line 5, in <module>\n",
      "    from langchain_chroma import Chroma\n",
      "  File \"c:\\Users\\w4rlo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain_chroma\\__init__.py\", line 6, in <module>\n",
      "    from langchain_chroma.vectorstores import Chroma\n",
      "  File \"c:\\Users\\w4rlo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain_chroma\\vectorstores.py\", line 28, in <module>\n",
      "    from langchain_core.documents import Document\n",
      "  File \"c:\\Users\\w4rlo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain_core\\documents\\__init__.py\", line 6, in <module>\n",
      "    from langchain_core.documents.base import Document\n",
      "  File \"c:\\Users\\w4rlo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain_core\\documents\\base.py\", line 17, in <module>\n",
      "    class BaseMedia(Serializable):\n",
      "  File \"c:\\Users\\w4rlo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pydantic\\v1\\main.py\", line 221, in __new__\n",
      "    inferred = ModelField.infer(\n",
      "               ^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\w4rlo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pydantic\\v1\\fields.py\", line 506, in infer\n",
      "    type_=annotation,\n",
      "       ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\w4rlo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pydantic\\v1\\fields.py\", line 436, in __init__\n",
      "    def get_default(self) -> Any:\n",
      "        ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\w4rlo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pydantic\\v1\\fields.py\", line 546, in prepare\n",
      "    # self.type_ is currently a ForwardRef and there's nothing we can do now,\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\w4rlo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pydantic\\v1\\fields.py\", line 570, in _set_default_and_type\n",
      "    if default_value is not None and self.type_ is Undefined:\n",
      "                    ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\w4rlo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pydantic\\v1\\fields.py\", line 439, in get_default\n",
      "    @staticmethod\n",
      "               ^^^\n",
      "  File \"c:\\Users\\w4rlo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pydantic\\v1\\utils.py\", line 693, in smart_deepcopy\n",
      "  File \"c:\\Users\\w4rlo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\copy.py\", line 172, in deepcopy\n",
      "    y = _reconstruct(x, memo, *rv)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\w4rlo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\copy.py\", line 271, in _reconstruct\n",
      "    state = deepcopy(state, memo)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\w4rlo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\copy.py\", line 146, in deepcopy\n",
      "    y = copier(x, memo)\n",
      "        ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\w4rlo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\copy.py\", line 231, in _deepcopy_dict\n",
      "    y[deepcopy(key, memo)] = deepcopy(value, memo)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\w4rlo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\copy.py\", line 161, in deepcopy\n",
      "    rv = reductor(4)\n",
      "         ^^^^^^^^^^^\n",
      "TypeError: cannot pickle 'classmethod' object\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\w4rlo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2120, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\w4rlo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1435, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\w4rlo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1326, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\w4rlo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1173, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\w4rlo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1088, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\w4rlo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 970, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "    ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\w4rlo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 792, in lines\n",
      "    return self._sd.lines\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\w4rlo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\w4rlo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\stack_data\\core.py\", line 734, in lines\n",
      "    pieces = self.included_pieces\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\w4rlo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\w4rlo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\stack_data\\core.py\", line 681, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\w4rlo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\w4rlo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\stack_data\\core.py\", line 660, in executing_piece\n",
      "    return only(\n",
      "           ^^^^^\n",
      "  File \"c:\\Users\\w4rlo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\executing\\executing.py\", line 116, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "os.environ.get(\"OPENAI_API_KEY\")\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "vector_store = Chroma(embedding_function=embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langgraph.graph import START, StateGraph\n",
    "from typing_extensions import List, TypedDict\n",
    "\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only = bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "\n",
    "docs = loader.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "all_splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = vector_store.add_documents(documents=all_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/langsmith/client.py:253: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context: List[Document]\n",
    "    answer: str\n",
    "\n",
    "class RetrieverTool:\n",
    "\n",
    "    def __init__(self, vector_store):\n",
    "        self.vector_store = vector_store\n",
    "        self.ID = 1 #to identify between one retriever to another\n",
    "\n",
    "    def retrieve(self, state: State):\n",
    "        retrieved_docs = self.vector_store.similarity_search(state[\"question\"])\n",
    "        return({\"context\": retrieved_docs})\n",
    "\n",
    "\n",
    "retriever_one = RetrieverTool(vector_store=vector_store)      \n",
    "\n",
    "def retrieve(state: State):\n",
    "    retrieved_docs = vector_store.similarity_search(state[\"question\"])\n",
    "    return({\"context\": retrieved_docs})\n",
    "\n",
    "def generate(state: State):\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
    "    response = llm.invoke(messages)\n",
    "    return ({\"answer\": response.content})\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "graph_builder.add_sequence([retriever_one.retrieve, generate])\n",
    "graph_builder.add_edge(START, \"retrieve\")\n",
    "graph = graph_builder.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'How ReAct works?', 'context': [Document(id='78eb9bbe-9d28-4544-95a6-08963e804015', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='ReAct (Yao et al. 2023) integrates reasoning and acting within LLM by extending the action space to be a combination of task-specific discrete actions and the language space. The former enables LLM to interact with the environment (e.g. use Wikipedia search API), while the latter prompting LLM to generate reasoning traces in natural language.\\nThe ReAct prompt template incorporates explicit steps for LLM to think, roughly formatted as:\\nThought: ...\\nAction: ...\\nObservation: ...\\n... (Repeated many times)'), Document(id='1e6aadd2-b9ae-4628-ac1a-7715b46fc1aa', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Fig. 2.  Examples of reasoning trajectories for knowledge-intensive tasks (e.g. HotpotQA, FEVER) and decision-making tasks (e.g. AlfWorld Env, WebShop). (Image source: Yao et al. 2023).\\nIn both experiments on knowledge-intensive tasks and decision-making tasks, ReAct works better than the Act-only baseline where Thought: … step is removed.\\nReflexion (Shinn & Labash 2023) is a framework to equip agents with dynamic memory and self-reflection capabilities to improve reasoning skills. Reflexion has a standard RL setup, in which the reward model provides a simple binary reward and the action space follows the setup in ReAct where the task-specific action space is augmented with language to enable complex reasoning steps. After each action $a_t$, the agent computes a heuristic $h_t$ and optionally may decide to reset the environment to start a new trial depending on the self-reflection results.'), Document(id='32f50ca0-8501-4ca9-afba-61cfb42a7631', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Case Studies#\\nScientific Discovery Agent#\\nChemCrow (Bran et al. 2023) is a domain-specific example in which LLM is augmented with 13 expert-designed tools to accomplish tasks across organic synthesis, drug discovery, and materials design. The workflow, implemented in LangChain, reflects what was previously described in the ReAct and MRKLs and combines CoT reasoning with tools relevant to the tasks:\\n\\nThe LLM is provided with a list of tool names, descriptions of their utility, and details about the expected input/output.\\nIt is then instructed to answer a user-given prompt using the tools provided when necessary. The instruction suggests the model to follow the ReAct format - Thought, Action, Action Input, Observation.'), Document(id='a105ed4e-eaa4-4128-a96f-c9ffa321028f', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='They also discussed the risks, especially with illicit drugs and bioweapons. They developed a test set containing a list of known chemical weapon agents and asked the agent to synthesize them. 4 out of 11 requests (36%) were accepted to obtain a synthesis solution and the agent attempted to consult documentation to execute the procedure. 7 out of 11 were rejected and among these 7 rejected cases, 5 happened after a Web search while 2 were rejected based on prompt only.\\nGenerative Agents Simulation#\\nGenerative Agents (Park, et al. 2023) is super fun experiment where 25 virtual characters, each controlled by a LLM-powered agent, are living and interacting in a sandbox environment, inspired by The Sims. Generative agents create believable simulacra of human behavior for interactive applications.\\nThe design of generative agents combines LLM with memory, planning and reflection mechanisms to enable agents to behave conditioned on past experience, as well as to interact with other agents.')], 'answer': 'ReAct works by extending the action space of LLM to include task-specific discrete actions and the language space for generating reasoning traces in natural language. It prompts LLM to follow explicit steps for thinking, acting, and observing in a predefined format. ReAct performs better than the Act-only baseline in experiments on knowledge-intensive and decision-making tasks.'}\n",
      "ReAct works by extending the action space of LLM to include task-specific discrete actions and the language space for generating reasoning traces in natural language. It prompts LLM to follow explicit steps for thinking, acting, and observing in a predefined format. ReAct performs better than the Act-only baseline in experiments on knowledge-intensive and decision-making tasks.\n"
     ]
    }
   ],
   "source": [
    "response = graph.invoke({\"question\": \"How ReAct works?\"})\n",
    "print(response)\n",
    "print(response[\"answer\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
